## Reference
### Tool1
https://phiresky.github.io/neural-network-demo/
### Tool2
https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.64443&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false
### Softmax as the activation function in the last layers of multi-class problems
https://www.analyticsvidhya.com/blog/2021/04/introduction-to-softmax-for-neural-network/

## Should read [P.413 ~ 459]
https://github.com/probml/pml-book/releases/latest/download/book1.pdf

```
In the forward propagate stage, the data flows through the network to get the outputs. 
The loss function is used to calculate the total error. Then, we use backward propagation algorithm to 
calculate the gradient of the loss function with respect to each weight and bias.
```
